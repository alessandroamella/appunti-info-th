Iniziamo. Ok. Dubbi sulla lezione della scorsa volta? Alri, abbiamo fatto cose semplici. Facciamo quick recup oggi e poi e poi vediamo gli argomenti nuovi. Ok. Allora, abbiamo iniziato a definire classi di complessità che sono sottoinsiemi sostanzialmente delle classi di decidibilità, no? È una sottoclasse di R. Noi fra tutti i problemi decidibili ci chiediamo quale sia facile, quale sia difficile. Ok? E abbiamo definito computation time di Turing machines, running time di Turing machines, time functions e poi abbiamo inserito, abbiamo fatto questa distinzione di cosa è calcolabile in tempo deterministico, cosa è calcolabile in tempo non deterministico e abbiamo introdotto le classi time e di time. Ok? Come casi questa è la definizione generale, eh, end time, tutto ciò che è decidibile da una macchina non deterministica secondo una certa funzione di tempo TN e di Time è tutto ciò che è decidibile da una macchina deterministica in running time bigo ddn. Ok, avevamo definito così. Queste sono classi generali perché ci permettono di definire ciò che è risolvibile in tempo polinomiale, ciò che è risolvibile in tempo esponenziale, doppiamente esponenziale, triplamente esponenziale e così via in tempo deterministico e non deterministico. Abbiamo poi individuato un paio di classi che sono p ed np in cui abbiamo che p è l'insieme di tutti i problemi di decisioni decidibili. in tempo polinomiale deterministico da una macchina di Touring. NP sono tutti problemi di decisione decidibili da macchine di Touring non deterministiche in tempo polinomiale. Vi ricordo che NP non significa non polinomiale, ma significa non deterministic polynomial. Ok? Negli anni la definizione di NP è stata cambiata, ne è stata data una che non fa riferimento alle macchine non deterministiche, questa la vedremo nelle prossime lezioni, eh che è una definizione quindi che ci sgancia dal fatto che una macchina non deterministica non si possa costruire. Ok? Quindi noi in realtà abbiamo una definizione equivalente di NP che eh non necessita di far riferimento a macchine non deterministiche. Queste due definizioni sono equivalenti, poi le vedremo. Ok? Per come è intuibile noi abbiamo che P è un sottoinsieme di NP. Ok? Quindi qua abbiamo l'insieme R dei problemi decidibili. Poi qui c'abbiamo P e qui c'abbiamo NP. Ok? Vi è chiaro perché P sia un sottieme di NP? Perché tutto quello che può essere fatto in tempo polinomiale deterministico, può essere anche fatto in tempo non deterministico polinomiale. Quindi questa questo contenimento è abbastanza naturale. La relazione apposta, cioè se NP stia dentro P, sia un sottinsieme di P da cui seguirebbe che P è uguale a NP. Questa è una cosa che è è un problema sostan è un problema correntemente aperto. Allora, riguarda è una cosa che abbiamo già più o meno affrontato quando abbiamo visto la simulazione di macchine non deterministiche da parte di macchine deterministiche. Allora, se vi ricordate, noi abbiamo che il costo della simulazione in quel caso è di tipo esponenziale e qui il problema è essenzialmente lo stesso. Noi abbiamo che i linguaggi di NP sono decidibili da macchine di Touring non deterministiche in tempo polinomiale. Se noi le simulassimo nel modo in cui abbiamo visto, noi avremmo una macchina deterministica in grado di riconoscere, di decidere lo stesso linguaggio in tempo esponenziale. Ok? Quindi, da un punto di vista della decidibilità del linguaggio, il linguaggio sarebbe comunque decidibile, però l'overhead di tipo esponenziale non ci permette di collocare il linguaggio dentro la classe P. Ok? Allora, ma ciò non significa che un linguaggio di NP sicuramente non sta in pieno? Questo perché non abbiamo ancora nessuno ha mai dimostrato che non sia possibile non sia possibile risolvere in tempo polinomiale deterministico un problema NP tosto, tra virgolette, ok? Cioè ci manca, noi sappiamo fare una simulazione in tempo esponenziale, però nessuno ha mai trovato un modo più furbo di quello. Ok? Quindi si ritiene che non sia possibile perché perché le menti più grosse che l'informatica teorica ha visto negli ultimi decenni ci ha sbattuto la testa per 60 anni. Il problema se pis ugual n risale agli anni 60. la gente iniziava a chiedersela questa cosa. Cioè agli anni negli anni 50 c'è un carteggio fra Gedel e von Neuman in cui Gedel, Kart Gedel, quello del teorema di Gedel, diceva a Von Neuman, "Guarda, c'è questo problema se questi problemi qua si possono risolvere in tempo polinomiale o meno." E Gedel diceva von Neyman, "Secondo me si può fare". Però a quel tempo non si sapeva assolutamente niente. Una decina di anni dopo, in un articolo di Edmund riesce la stessa questione del fatto se i problemi risolvibili, in quel caso la soddisfacbilità che abbiamo visto la scorsa volta, fosse risolvibile in tempo polinomiale e o meno. E lui dice la mia congettura è che non sia possibile, eh ho dei dati concreti per dire una cosa del genere. No, semplicemente la butto così, secondo me non si può fare. Di qualche anno dopo è un lavoro di Carp in cui viene definito il concetto di NP hardness, NP completezza che vedremo stamattina in quel suo lavoro dice "Secondo me è una cosa che non ci riusciremo mai a farla. Ho degli indizi forti per cui questa cosa non può accadere. Non ho una dimostrazione. Di fatto una dimostrazione non è mai stata trovata. Nessuno ha mai dimostrato che non sia possibile risolvere un problema np di quelli difficili in in tempo polinomiale. Di conseguenza, la questione se P sia uguale a NP è una questione correntemente aperta. Ok? Quindi la similitudine che noi abbiamo, per esempio, rispetto a R re R che avevamo visto la scorsa volta, per cui noi abbiamo la certezza che R ed R siano distinti. per P ed non lo sappiamo, lo ipotizziamo perché dopo tanti anni di lavoro nessuno è mai riuscito a tirar fuori un algoritmo polinomiale per un problema e né piuttosto, quindi la nostra assunzione è che non sia possibile. Ciò nonostante nessuno ha mai dimostrato che questa cosa non sia possibile. Ok? Quindi è uno dei problemi è il problema aperto nel all'interno dell'informatica teorica perché il fatto che noi non sappiamo se P sia strettamente contenuto in n o meno fa sì che tutta una serie di altri risultati di informatica teorica di classi di complessità la cui distinzione e conseguenza di P diverso da NP è tutta roba che rimane aperta, cioè non semplicemente non lo sappiamo. ipotizziamo che siano tutte classi distinte perché non ci siamo mai riusciti, però la certezza completa non l'abbiamo. Ok? Allora, in questo fantastico viaggio nel tentativo di eh distinguere P da NP, insomma, la gente l'aveva sospettato che fossero diversi e allora ci sono tutti dei lavori degli anni 70-80 per cercare di separare queste classi e nessuno è mai riuscito ad arrivarci. si sono inventati dei concetti che permettessero un attimo di capire se le cose fossero distinte o meno. E una delle intuizioni che ebbero o almeno una delle strade che cercarono di percorrere è: "Ok, ma dentro la classe NP ci stanno dei problemi che sono molto più difficili degli altri." Ok? Magari se riusciamo a provare che anche uno solo di questo sta dentro P, allora avremo il collasso di P np. Ok? e quindi si inventarono questa nozione che adesso introdurremo e si basa su un altro concetto che dobbiamo un attimo specificare. Quindi voi ve lo ricordate il concetto di riduzione? Sì. Ok. e lo specifichiamo un pochettino perché è quello che ci serve ora, che è il concetto di riduzione polinomiale che è la stessima cosa di una riduzione polinomiale. L'unica cosa è che deve essere calcolabile in tempo polinomiale. Allora, siano A e B due linguaggi, una riduzione polinomiale da A una funzione fpa stringhe su stringhe tale che f è calcolabile in tempo polinomiale E inoltre per ogni stringa w, se w appartiene ad A, se è solo se e il trasformato di w secondo F appartiene a B. Ok? Quindi è la stessa cosa. Stiamo semplicemente aggiungendo il vincolo che la trasformazione possa essere calcolata in tempo polinoviale. Vi ricordo che noi il concetto di calcolabilità l'avevamo legato alla nozione di trasduttore, quindi di macchine di touring che sono in grado di calcolare un certo risultato. Bene, adesso stiamo semplicemente dicendo che quel trasduttore che implementa f deve rannare in tempo polinomiale, ok? Il numero di passi deve essere polinomiale nella taglia dell'input. Eh, denotiamo la riduzione con A uguale pice PB. Quindi, quando scriveremo questo, significa che A si riduce a B in tempo polinomiale. Ok? Per il resto è la stessa cosa, deve mappare istanze sì su istanze sì, istanze no istanze no. L'unico vincolo è che ciò avvenga in tempo polinomiale. Ok? Quello maggiore uguale con un p con un pice Q. Sì, sì, sì, sì, sì. Ok. Allora, definito ciò, definito il concetto di riduzione polinomiale, possiamo, ok, possiamo introdurre il concetto di NP Hardness. Ok? Allora, è un concetto molto semplice il concetto di NP Hardness. è definito in questo modo. Un linguaggio L è NPRD. Se per ogni linguaggio L'O appartenente ad NP è possibile ridurre polinomialmente L' a L. Ok? Quindi molto semplice. Un linguaggio è NP arduo o NP hard se esiste una riduzione da un qualsiasi linguaggio di NP a L. Ok? Intuitivamente questa cosa significa che L è almeno difficile quanto tutti i linguaggi di NP. Ok? È chiaro questo? Ripetiamo, un linguaggio L è NP hard se per ogni linguaggio L'O appartenente ad NP esiste una riduzione da L'O e questa riduzione ovviamente deve essere polinomiale, ok? Da adesso in poi tutte le riduzioni a cui faremo riferimento sono riduzioni polinomiali, ok? Forse solo se riusciamo ad arrivare una a fare una cosa un po' più sofisticata, parleremo di un altro tipo di riduzione, però al momento è polinomiale. Prego. Questo significa che ogni linguaggio appartenente NP che non sia L può ridurre L. Allora, in questo caso NP oppure ne basta uno? Perché per ogni per ogni tutti si devono ridurre, ok? Quindi tutti i linguaggi di L'O si devono ridurre a L, che è un po' rognosa questa definizione perché come cavolo li riduciamo tutti quanti, però vedremo che abbiamo dei trucchi, li vedremo stamattina. Ok? Quindi questa è la definizione di NP Hardness. Altra definizione che è una cosa che probabilmente avete visto, NP completeness completeness. Yes. Ed è più completezza. Un linguaggio L e NP complete. Se 1 L appartiene ad NP e 2. Voi vedete? Sì. L e NP hard. Ok, quindi qual è la differenza nella definizione fra un linguaggio NP hard e un linguaggio NP complet? Cerchiamo di discernere esattamente che differenza c'è, perché spesso la gente non troppo esperta pensa che siano la stessa cosa. Ok? Quindi, date le definizioni che abbiamo scritto là, che differenza c'è fra un linguaggio NP hard e un linguaggio NP complet appartiene NP. L appartiene a NP, cioè per essere un linguaggio NP completo non solo deve essere NP arduo, ma deve essere anche un linguaggio di NP. Di conseguenza, un linguaggio NP arduo è un linguaggio che è almeno difficile quanto tutti i problemi di di NP. Un linguaggio NP completo è un linguaggio che è almeno difficile quanto tutti i linguaggi di NP ed inoltre è un linguaggio di NP. Quindi un linguaggio NP completo è un linguaggio che è tra i più difficili di NP. Questa è la differenza. Ad esempio, ve lo ricordate? Ve lo ricordate il il linguaggio universale? Cos'è il linguaggio universale? L'insieme delle coppie di macchine string la macchina. Esattamente l'insieme, il linguaggio delle coppie, macchine e stringhe tale che la macchina accetti la stringa. È vero, o no, che il linguaggio universale è NP Hard? Sì, perché è almeno tosto quando tutti i linguaggi di NP. Fra l'altro è molto più tosto, però è NP algo, non è NP completo perché quel linguaggio, non essendo ricorsivo, non può stare nemmeno dentro NP. Ok? Quindi la nozione di NP hardness è un po' più lasca. La nozione di NP Hardness ci dice semplicemente che un linguaggio è almeno difficile quanto tutti i linguaggi di NP, ma potrebbe essere anche molto più difficile. Per dire che un linguaggio è tra i più tosti di NP, ci serve che quel linguaggio NP arduo sia anche dentro NP. Allora, in quel caso noi parliamo di NP completezza. Ecco perché noi eh usiamo due termini. Ho visto spesso in giro che la gente confonde, cioè pensa che NP hardness, NP completeness sia la stessa cosa. Non è la stessa cosa, come potete vedere dalle definizioni. Prego. Qui i problemi NP hard sono tutti i problemi da NP più i problemi Nessi. Sì, sì, sì, sì, sì, sì. Esattamente, esattamente. Ehm. Ok, ok. Allora, questa nozione di NP hardness ed NP completezza ci permette di iniziare a vedere, siccome la la definizione di NP completezza sostanzialmente ci dice che un linguaggio NP completo se eh è uno dei linguaggi più tosti di NP, ok? è uno dei linguaggi più difficili, ma che sta dentro NP. Quella nozione venne utilizzata per trovare una caratterizzazione sul fatto se P sia uguale ad NP. Ok? Però, cioè, questo è un risultato abbastanza semplice che vediamo ora, ma più di quello non è che siamo riusciti a trovare. Ok? Poi c'è tutta una cosa sui linguaggi sparsi, ma quello non vedremo. Ok? Allora, teorema [Musica] teorema sia L un linguaggio NP completo. Allora, L appartiene a P se e solo se P è uguale a NP. Ok? Quindi se noi abbiamo un linguaggio NP completo, quindi uno dei linguaggi più tosti della classe NP, questo linguaggio sarà decidibile in tempo polinomiale solamente se e solo se NP collassa su P. Cioè che queste due classi sono uguali. Ok. Come si chiama teorema? Come si chiama? Teorema. Non ha un nome particolare. Yes. Non ho capito una cosa, però cioè lei ha iniziato la lezione dicendo che eh abbiamo ancora dimostrato che p ug, ma quindi non consulteremo stando stiamo indicando che semmai qualcuno fosse in grado di risolvere il tempo polinomiale un problema np completo, allora come corollario otterrebbe che p è uguale a n. Questo significa, cioè questo questo problema iniziale come questo è il problema iniziale, no? Il problema il problema iniz è più o meno legato perché comunque la cosa le cose sono legate in quanto P ug np se solo se riesco a risolvere in tempo polinomiale il problema np completo perché siccome c'è la doppia implicazione la questione è equivalente. Quindi questo teorema ci sta dicendo che derimere la questione se p sia uguale a n o meno equivale a essere in grado o meno di risolvere in tempo polinomiale un problema n completo. Chiunque mai ci dovesse riuscire avrebbe risolto anche la questione. Io ricordo che quando ero un giovane dottor il mio professore mi girò un paper di uno che sosteneva di aver risolto un problema e più completo in tempo patrimoniale. ci buttai due settimane per trovare l'errore nell'algoritmo e poi gli rispondemmo il tuo algoritmo non funziona per la tosta. Ok, però c'è gente che ci prova ultimamente. Qual è la questione? in tanti ci provano, ormai crediamo che P sia diverso da NP e quando pubblicano cose o sostengono di di avere questo risultato che P sia uguale a NP, riteniamo che non sia il caso. Poi tutto può accadere, però nessuno c'è mai riuscito. Di recente mi è arrivato un altro che mi segnalava di aver risolto la questione. Si leggeva, era scritta con i piedi, insomma era veramente poco formale. Ok. Alright. Quindi noi dobbiamo ora dimostrare questa cosa che un linguaggio è NP completo se è solo se la classe P è uguale ad NP. Ok? Alright, dimostrazione. Partiamo dalla dal verso semplice, ok? Cioè, dimostriamo che se P è uguale a NP, allora quindi se P è uguale a NP, allora il linguaggio L appartiene a P. Allora, questo è semplicissimo da dimostrare perché se siccome L è un linguaggio NP completo, allora L appartiene a NP. Di conseguenza, se P fosse uguale a NP, avremmo che L appartiene a P. Ok? Quindi questo è un verso facilissimo. Ok? L'altro verso è più interessante. Allora, dimostriamo che cosa? Che se L appartiene a P, allora P è ugp. Questo è il verso che dimostriamo di questa di questo teorema. Ok? Allora, noi sappiamo che P è un sottinsieme di NP, ok? Questo lo sappiamo, è semplice. Ok? ci per dimostrare che P sia uguale a NP, ci manca da mostrare che cosa? Che NP è un sottinsieme di P. Ok? Quindi se noi partendo da qui, quindi se riusciamo, questo ve lo indico così ve lo trovate scritto. Se riusciamo a mostrare che il fatto che l appartenga a P implica che NP è un sottinsieme di P, allora il gioco sarebbe fatto. Ok? Questa quindi è l'implicazione che vogliamo mostrare. Se mostriamo che questa cosa è in piedi, allora otteniamo che il fatto che L appartenga a P implica che P è uguale a NP. Ok? È chiaro per tutti la manovra che stiamo facendo? Alri, partiamo da questo. Siccome L è NP completo, L è NPH2 per definizione. Ok? Se L è NP arduo, allora per definizione, per ogni linguaggio L'O appartenente ad NP, noi abbiamo che L'O si riduce polinomialmente a L. Ok? Quindi se si riduce polinomialmente a L, vuol dire che c'è una funzione di trasformazione f calcolabile in tempo polinomiale deterministico che mappa istanze sì di L'O istanze sì di L e istanze no di L' su istanze no di L. Ok? Adesso considerate questa macchina. Facciamo sempre le nostre macchinone. Quindi abbiamo in input w la facciamo processare ad f. Qui esce F di W e poi qua mettiamo la macchina che decide L. Ok? Quindi questa è una macchina che prende in input W, la trasforma secondo F per ottenere F. Dopodiché viene messa viene mandata in input alla macchina che decide il linguaggio L. Se ML risponde sì, rispondiamo sì. Se ML risponde no, rispondiamo no. Che linguaggio sta decidendo la macchina quella grossa? Se F è una trasformazione che trasforma le istanze di L'O in istanze di L L'O, questa macchina eh questa macchina decide L'O. Ok? Questa festa eh è la funzione di trasformazione che trasforma che rimappa le istanze di L'O. Quindi la macchina L'O è la macchina cioè ML'O, questa qui grossa, composta in questo modo è una macchina che decide L'O in cui L'O che cos'è? È un linguaggio generico di NP. Ok? Quello che noi ci chiediamo ora è: ma ML'O esegue in tempo polinomiale o no? Adesso andiamo a verificare, ok? Perché abbiamo una macchina che decide L'. Se ML' ha un running time polinomiale, allora L'O appartenrebbe a P. Ok? Vediamo un po'. Quindi, come prima fase del calcolo che fa la macchina? Prende W e da questa ottiene il trasformato di W secondo F. Ok? Quanto tempo ci mettiamo a calcolare F? Polinomiale. Polinomiale. Ok. Diciamo che è un big o di N^ C dove N lo scriviamo qua, N è la taglia di W. Ok? Adesso ci chiediamo questo. Se noi calcoliamo f w e noi qui ovviamente c abbiamo che c è maggiore o uguale di 1 ed è fixed, è una costante, eh non cambia rispetto al limite. Adesso se noi calcoliamo in bigo di n^ c f, quanto può essere grande l'output di questo calcolo? Ripeto, abbiamo W che viene passata alla funzione f. Questa macchinetta ci gira sopra, calcola f, lo fa in tempo big o di N^ C. Il risultato che spuda fuori, no, non lo so, magari chiamiamola Y, dai, così ci chiamiamo, ci capiamo quantoè grossa Y. Quant'è la taglia di Y? C e n^ c alla massimo perché quello è il tempo, no? Cioè se la macchina fa big o di n^ c passi non può sputare una y di taglia esponenziale, non avrebbe il tempo di scriverla in output. Ok? Quindi noi abbiamo che la trasformazione di F second W è bigo. Quindi abbiamo che la taglia di F wig o di N^ C. Ok? È chiaro? Perché? Ripeto, noi la dobbiamo generare sta f di w e ci serviranno dei passi, dei passi anche per scrivere l'output. Ok? Io non posso scrivere una cosa più lunga del tempo che ho a disposizione. Molto semplice, è chiaro? Ok? Quindi, una volta che abbiamo f la la mandiamo in input ad mdl. Ok? MDL in indipendentemente dal suo input, qual è il suo running time? polinomiale. È polinomiale perché stiamo assumendo che L sia una un linguaggio in P, quindi eh assumiamo running time di ml o di N^ D. Cosa ricevi input? La macchina ML ML F. Quanto è grande F? E N^ C. Quindi rispetto alla taglia iniziale di W, in quanto tempo ranna la macchina? La macchina ML lì dentro big o di cosa? Di N^ C. alla d, ok? Che è big o d * d. Chiaro? Vi sottolineo che C e D sono delle costanti, sono fissate, non dipendono dall'input, quindi quello è un polinomio. Quindi il running time totale, qui non c'è spazio, il running time totale di questa macchina lo faccio in un altro colore, così non ci confondiamo. Quant'è Big? O di Oplà n^ C. + n^ c * d. Ok? Che è un polinomio o un esponenziale? Un polinomio. Quindi noi abbiamo due cose, ci siamo quasi, eh? ML' A è una macchina che in effetti decide L'O. decide L'O in tempo polinomiale. Quindi noi abbiamo che tramite la rudizione da L'O noi siamo in grado di risolvere il linguaggio L'O in tempo polinomiale. Ma L'O era un linguaggio generico di NP. Ciò vuol dire che qualsiasi sia un linguaggio di NP, noi tramite L siamo in grado di riconoscerlo, di deciderlo in tempo polinomiale, da cui NP è un sottoinsieme di P. Combinato a quello che già noi sappiamo che P sia un sottinsieme di NP, otteniamo che P è uguale a NP. Chiaro? Eh, faccio un bel continua. Questo l'avevamo già fatto. Ok, facciamo quest'altra cosa e poi ci fermiamo. Allora, quello che abbiamo visto quindi dal teorema precedente è che la domanda su quello che abbiamo appena fatto. Yes. Eh, la prima domanda è al punto ho capito una piccola cosa. Se noi eh, appunto abbiamo un output che è O C O NC, sì. Cioè, come facciamo a computarlo se il tempo dizione è grande quanto l'al? Quello è B, quindi al massimo. Sì, quelle sono delle stime a comband che ha, però quello che di sicuro non può accadere è che si possa generare in tempo polinomiale un output esponenziale. Quello non può accadere, magari, cioè, non faremo esattamente in decen faremo di meno, ok? Poi dipende, dipende dalla trasformazione, magari la trasformazione prende l'input e lo copia, quindi è in grado di fare, insomma, dipende dalla trasformazione in sé, ma l'unica cosa che si, cioè una cosa di cui siamo certi è che in tempo polinomiale non possiamo generare un output esponenziale. La seconda domanda era eh non ho capito bene come conclude la dimostrazione. Ok? Una volta che noi eh dimostriamo che l ML', quindi è chiaro che ML'O decide L'O per come è definita. Dobbiamo semplicemente abbiamo pure mostrato che ML'O ha un running time di tipo polinomiale. Questo pure è chiaro? Sì, scusi. Ok. Allora, che cosa significa? Che L'O è un linguaggio generico di N' di NP. che tramite la riduzione ad l può essere risolto il tempo può essere deciso il tempo polinomiale. Ok? Ma L'O è un linguaggio generico di NP. Di conseguenza, un qualsiasi linguaggio di NP, tramite questo trucco si può decidere in tempo polinomiale, semmai dovesse esistere un linguaggio NP completo decidibile in tempo polomiale. La ringrazio. A quel punto NP e insieme tutti. Ok? Allora, questa nozione di NP completezza sembra abbastanza interessante, ok? perché ci permette di individuare quali siano eh eh sì, ci permette di individuare quali siano i linguaggi eh difficili della classe NP e a quel punto essere in grado di stabilire, no, semmai dovessimo essere in grado di trovare un algoritmo che risolve in tempo polinomiale un problema NP completo, saremmo in grado di dire ok, P è uguale a NP. Questa cosa qua ci risolverebbe tutta una serie di questioni perché problemi tosti saremmo in grado di risolverli in tempo polinomiale e noi abbiamo tutta una serie di problemi tosti che a risolverli in tempo polinomiale ci verrebbe parecchio comodo. Ok? Ecco perché la gente si cè butata con poco successo perché nessuno c'è mai riuscito. Però la questione qui è che la definizione di NP completezza che si basa sulla definizione di NP hardness è un po' stigna perché un linguaggio è NP arduo solamente se tutti i linguaggi di NP si riducono a lui, cioè quindi è un po' difficile andarsi a verificare se un linguaggio sia NP completo o meno, NP arduo o meno. Detto ciò, ci stanno, è stato fatto. E uno di questi linguaggi è propriamente qua introducco prima o dopo, uno di questi linguaggi che NP NP completo è SAT. Allora, il linguaggio SAT è il linguaggio che abbiamo introdotto la scorsa volta, ok? Che è il linguaggio delle formule buleane in forma normale congiuntiva. Esiste una dimostrazione che non vediamo per il momento, perché ora ci vogliamo concentrare su altro, per il del fatto che SAT sia un problema NP argo ed NP completo. Di fatto è stato il primo linguaggio N mostrato essere NP completo. In quel paper venne definita la nozione di NP completezza e l'autore mostrò SAT e NP completo che è abbastanza sofisticata, richiederà una lezione intera, la vedremo più avanti. Ok? Fidatevi, SAT è NP completo. Quindi noi abbiamo una sorgente NP completa, cioè noi sappiamo che esiste un linguaggio, no, NP completo. La cosa interessante è che una volta che ne abbiamo uno, in realtà mostrare che altri linguaggi siano NP ardui è più semplice perché possiamo sfruttare le riduzioni. Ok? Questa è l'intuizione. Allora, la definizione richiederebbe per mostrare che un linguaggio NP alto che noi fossimo in grado di mostrare che esiste una riduzione da qualsiasi linguaggio NP. Questo è un casino, cioè ci vuole veramente tanto, eh, perché dice possibile che tutti Sì, tutti per SAT è stato fatto. Esiste una riduzione molto sofisticata, abbastanza generale che fa vedere che qualsiasi linguaggio DNP consideriamo è possibile ridurlo a SAT, però è veramente sofisticato. Una volta che abbiamo SAP è possibile dimostrare l'NP hardness di altri problemi tramite altre vie, tramite riduzioni. L'intuizione è che siccome una riduzione sostanzialmente ci mostra che è un se noi riduciamo A a B, noi abbiamo che l'intuizione è che B sia almeno difficile quanto A. Quindi, se il problema di partenza sarà NP arduo, il problema di arrivo sarà NP arduo. Adesso vediamo un po' più il dettaglio, però sostanzialmente questo è il risultato che ci serve per toglierci le patate dal fuoco, perché sennò se dovessimo essere in grado ogni volta di mostrare che un problema o un linguaggio è NP arduo tramite la riduzione da tutti i linguaggi della classe NP, sarebbe molto molto molto sofisticato e molto tedioso. Ok? Però per fare questa cosa ci serve un passaggio intermedio che è la proprietà di transitività delle riduzioni polinomiali. Prego. Quindi la prospettivo invece di fare lazione soddispicata, a questo punto è ridurre SAT all'altro problema. Ridurre SAT all'altro problema e poi una volta che iniziamo ad avere i primi problemi NP completi o NP ardui e usare quest'altri questi altri per mostrarne altri ancora. Cioè la dimostrazione di NP completezza da da definizione è stata fatta una volta sola in un in un paper del 71 da Stephen Cook mostrò che esatta NP completo. Da quel momento in poi tutte le dimostrazioni di NP hardness sono state fatte tramite catene di riduzione sostanzialmente. Ok? Tutto ciò per funzionare ha necessità di un risultato intermedio che è questo che è il teorema che è la transitività delle riduzioni polinomiali. Allora, molto semplice, siano A, B e C tre linguaggi. Se A si riduce polinomialmente a B e B si riduce polinomialmente al C, allora A si riduce polinomialmente a C. Ok? È chiaro? Dimostrazione molto semplice. Cosa abbiamo? Se A si riduce a polinomialmente a B, allora c'è una funzione f trasformazione che riduce a verso B. Questo per definizione di riduzione polinomiale. Supponiamo che il tempo di di trasformazione sia big o dn c per un c mag 1 fissato. Ok? D'altro canto, se B si riduce polinomialmente a C, allora c'è una funzione di trasformazione G che si esegue in O n^ D per un D> 1 fissato. Ok? Per mostrare che cosa vogliamo mostrare? Vogliamo mostrare che A si riduca polinomialmente a C. E da definizione noi abbiamo che A si riduce polinomialmente a C se è solo se esiste una riduzione tempo polinomiale da A verso C. Vogliamo mostrarla. La riduzione da AC è la composizione di G con F. Tutto qua. Ok? Quindi la riduzione da A verso C si ottiene applicando prima la funzione F su W e poi la funzione G su W. Ok? La infiliamo in un nostro trasduttore. Quindi che abbiamo? Abbiamo W che va impasto ad F. F tira fuori W. Questo va impasto a G e quello che tira fuori è G di F di W. Ok? Questa è la è la funzione G composto F. Ok? Quindi di fattibile è fattibile. Noi possiamo prendere la funzione famoso con la funzione G che sappiamo esistere. Ok? E quindi si tratta di fare un primo calcolo e un secondo calcolo. Quello che ci manca da verificare è se questa composizione di funzioni sia calcolabile in tempo polinomiale. Ok? Perché quello ci serve. Allora, il discorso c'è mostrare che la composizione di G con F sto andando troppo veloce. Seguite? Ok. per mostrare il cioè l'argomento che mostra che la composizione di Ged F si può fare in tempo polinomiale è sostanzialmente simile a quello che abbiamo mostrato nel problema di prima, ok? Nel nel teorema di prima. Allora, focalizziamoci sul calcolo di f. Ok? Questo qua in quanto tempo può essere fatto? O grande di N^ C. o di n^ c per assunzione. Ok? Qui facciamo la stessa considerazione. Quanto è grande stringa sputata fuori dal primo pezzo della formula? O è o grande di n^ c. La motivazione, vi ripeto, è semplicissima. Noi non possiamo generare un output più grande del tempo necessario a scriverlo. Ok? Se la macchina ranna in 10 passi non può sputare un output più grosso di 10 simboli, non ha il tempo per farlo. Ok? Quindi, se la funzione f wcolata in big o di n^ c, allora la taglia dell'output di questo calcolo è big o di n^ c. Ok? Secondo pezzo, dobbiamo fare G di F di w. Ok? Noi sappiamo che G può essere calcolata in big o n^ D. Quindi questa cosa che sarà? Big o di cosa? Di f W^ D che per composizione è big o NC^ D che è big O N^ C * D. Ok? Quindi una composizione di due trasformazioni polinomiali ci dà una trasformazione polinomiale. Ok? Adesso facciamo l'ultimo risultato e poi facciamo una pausa, ok? Dopodiché vedremo un po' di problemi e un po' di riduzioni. Quindi finiamo la parte teorica più teorica ora e poi vediamo un po' di roba. Ok? Ma allora come sfruttiamo questa proprietà? per quello che dicevamo prima, cioè per poter mostrare che un certo linguaggio sia NP arduo. Teorema sia a un linguaggio NP arduo. Ok? Se B è un linguaggio tale che A si riduce polinomialmente a B, allora B è NPR. Ok? Quindi questa è la proprietà che ci serve. È chiaro? Allora, da definizione, gli ultimi 5 minuti e poi ci fermiamo. Da definizione B per essere NP arduo deve succedere che tutti i linguaggi di NP si ridudino a lui. Quindi dobbiamo riuscire a mostrare che esiste una riduzione polinomiale da un qualsiasi linguaggio di NP verso B. Ok? Però sappiamo pure che A è un linguaggio NPRO, lo sappiamo come ipotesi del teorema. Quindi, poiché a e n arduo, per ogni linguaggio L'O appartenente ad NP, abbiamo che L'O si riduce polinomialmente ad A, ma da ipotesi noi abbiamo che A si riduce a B. Per il lemma di prima, per la composizione delle funzioni di riduzione avremo che cosa? Che L'O si riduce a da cui tutti i linguaggi di np si ridicono a B. È chiaro questo passaggio? Ripeto, per mostrare che B sia un linguaggio NPRO, noi dobbiamo far vedere che tutti i linguaggi di NP si riduano a B. O ci sbattiamo la testa e lo facciamo uno per uno o sfruttiamo un passaggio intermedio di un altro linguaggio de triangolo. Se A sappiamo essere NP algo, allora per definizione tutti i linguaggi di NP si riducono ad A. Se io poi so mostrare che A si riduce a B per composizioni di riduzioni, noi avremo che esistono delle riduzioni da un qualsiasi linguaggio di NP a B da cui P NP. Ok? Quindi nella totalità delle nostre dimostrazioni per dimostrare che un linguaggio sarà NP arduo, noi sfrutteremo questo. Noi ridurremo un linguaggio NP aguo noto al nostro linguaggio di interesse, perché fare le riduzioni da tutti i linguaggi NP c'è da uscire. Ok, prego. Possiamo quindi proseguire come corollario che vale anche per l'MP competenza teorema. Ah, dipende come lo vorrebbe teorema. Eh, NP completa, no. Se allora lo ponga in formato se allora se è questo al modo successo se A è un linguaggio e B appartiene NB completo EB appartiene NP ed esiste la riduzione allora anche B appartiene a NP completo. NP completo, sì. Cioè però lei deve sapere che B è NP completo, cioè non è conseguenza del teorema. Ah, ok. Cioè, se A è NP completo e A si riduce a B, allora B è NP ago, perché NP completezza è un caso più stringente di NPES. Ok, questa è la sua forma più generale, ok? intuitivamente, poi poi ci fermiamo. Se A è un problema NP arduo, ma nel senso di quelli che proprio sono catastroficamente difficili e costissimi, no? Come abbiamo detto prima, che un linguaggio NPGO non necessariamente sta dentro NP, no? Se io ho un linguaggio NPO estremamente tosto, lo posso sempre ridurre a un linguaggio NP completo? No, perché lauder Lauder la sì, perché un linguaggio NP alto potrebbe sempre linguaggio indecidibile e non è che lo posso ridurre a un linguaggio NP completo che è indecidibile. Ok? Quindi si deve stare molto attenti su queste cose. Infatti lo statement del teorema è se A è NP al e semmai dovesse esistere una riduzione da A, allora B è ancheo, ok? Perché non è detto che esista una riduzione da un problema NP alduo a un problema NP completo. In caso stiamo riducendo qualcosa di difficile a qualcosa di facile. Ok, fermiamoci qua a 10 minuti. Dai. Ok. Chiari i concetti fatti finora? [Musica] Yes. No, forse chiaro quello che abbiamo fatto finora. Vado troppo veloce. It's alr il pace. Va bene. Ok. Eh. Ok. Domanda che ho ricevuto durante l'intervallo. Ma sulle sui polinomi noi abbiamo detto che CD deve essere maggiore o uguale di 1? Ok? E lì stavo semplificando. Potenza intera di ci deve essere più di 0, quindi almeno √ n va benissimo, è pure quello polinomiale, ok? Quindi l'importante è che sia maggiore di 0, ok? Quello rende rende il problema polinomiale, cioè no, meglio. Quello che rende polinomiale è che l'esponente sia fissato, eh? Perché se l'esponente varia in base alla taglia dell'input, quello non è più polinomiale, eh, quello è esponenziale. Quindi l'esponente deve essere una cosa fissata. Se è fissata, allora è polinomial. Ok? Alright. Quindi nelle prossime lezioni andremo a dimostrare che data questa definizione di NP completezza, andremo a dimostrare una serie di problemi NP completi, ok? che sono problemi che in parte conoscete, in parte no, però vedremo che sono tutti problemi tosti, cioè sono tutti problemi per i quali un algoritmo polinomiale non esiste, nessuno se l'è mai inventato e molto probabilmente nessuno sarà mai in grado di inventarselo perché quello che riteniamo è che P sia diverso da NP e che quindi i problemi NP completi non possano essere risolti. in un tempo strettamente inferiore di esponenziale, ok? Cioè non pensiamo che ciò sia fattibile. Mi hanno chiesto, questo è interessante, ve la faccio, una rappresentazione grafica della relazione tra P, NP, NP completi, eccetera. Adesso io vi disegno quella che c'ho io in testa che mi aiuta un po'. Allora, io me la immagino così. Qui ci sta P, no? dice, "Perché lo disegni così e non un cerchio?" Perché mi piacciono i tramonti. Eh, faccio il so. Questo è NP. Ok? Allora, che cos'è NP arduo? Per me NP arduo è sono tutti problemi che sono almeno difficili quanto NP. Allora, io NPAD me lo immagino così che è il bordo di questa cosa qua più tutto quello che c'è fuori. Ok? NP arduo è il bordo più quello che c'è fuori. Detto, quindi pure i problemi indecidibili. Sì, pure i problemi indecidibili perché noi possiamo ridurre tutti i linguaggi di NP a problemi indecisibili. Ok? Quindi per me NP hardness è il bordo di NP e tutto quello che ci sta fuori. Ok? Perché nella mia rappresentazione visiva io ho che questi insiemi vanno crescendo e più sono grossi più sono verso l'esterno e più ci sono problemi difficili. Ok? Questi sono NP ardui e i problemi NP completi. Nella mia rappresentazione visiva, Certo, i problemi NP completi sono i problemi sul bordo di NP, ok? Quindi c'ho questa rappresentazione, c'è chi li rappresenta così, cioè ve li potete immaginare come volete, fra NP completo e questa cosa in alto NP. Fate come volete, no? Qualsiasi cosa viuta vi aiuti a rappresentare tramite metafora questi concetti, va bene? Io c'ho questa cosa del bordo. Per me i problemi NP completi sono il bordo di NP. Fuori di là c'è altro. Mo per dire, ad esempio, qua al di fuori ancora non l'abbiamo visto, potremmo affrontarlo. Qua c'è per esempio exponential time, che è una classe ancora più grossa. Vabbò, queste sono cose che forse poi vedremo. Ok. Alright. Allora, quello che andremo a fare, quindi, è dimostrare un po' di problemi NP ardui, NP completi e il tutto si baserà, il tutto partirà da cosa? dal fatto che SAT è NP completo, che ancora non l'abbiamo visto, fidatevi, NP completo. Vedremo la dimostrazione ci vorrà, sarà una dimostrazione bella lunga, eh, eh, però partendo da questa base che salta NP completo, possiamo iniziare a dimostrare che anche altri problemi sono NP completi e ne vedremo un po'. Oggi partiamo da questo qui tresat che è un problema intermedio che ci servirà poi per gli altri perché molti saranno dimostrati partendo da Tresat. Ok? Che differenza c'è fra SAT e Tre SAT? Vi ricordo che SAT è l'insieme delle formule buleane in CNF. CNF è forma normale congiuntiva, quindi sono formule fatte da clausole in congiunzione. Le clausole sono fatte da letterali in disgiunzione. Cos'è un letterale? È o una variabile buleana o il suo negato. Ok? Quindi quella è una formula in CNF. Una formula 3 CNF è una formula in CNF in cui ogni clausola contiene al più tre letterali. Ok? Quindi è un sotto caso, una cosa molto limitata. E noi abbiamo quindi che eh Sì, questa è la formula 3 CNF. Cos'è il problema 3 SAT? Il problema 3at è l'insieme di tutte le formule buleane in 3 CNF soddisfacile. Ok? Quindi decidere 3 SAT equivale a fare questa operazione data in input una formula in 3 CNF decidere se sia soddisfacbile o no. Questo è tre satat. Ok? Quindi è una variante di SA più semplice, di struttura più semplice, perché eh abbiamo che le clausole possono avere al più tre letterali, possono averne di meno, tipo che ne so, se prendiamo una formula f del tipo x1 or x2 or not x3 and not x2 or x4 4 and boh, x3 or x5. Questa è una formula in 3 cm, ok? Cioè la clausole devono essere al più tre letterali, poi possono essere pure di meno, però al +3. Ok? La cosa interessante è che si può dimostrare che 3at è NP completo. Quindi, nonostante la eh il vincolo sulla struttura della formula, noi abbiamo che questo problema, sebbene sia una variante di SAT semplificata in struttura, non è semplificata in complessità, cioè tra SAT e NP completo. Esattamente come esatto. Ok, lo dimostriamo perché vari altri problemi per dimostrarli NP completi è più facile mostrare una riduzione da 3 SAT che non da SAT. Ok. Ok. Ok. Allora, per dimostrare che 3at è NP completo, dobbiamo fare due cose che sono dimostrare NP e poi la riduzione sì e dimostrare che 3at NPES. Quindi per dimostrare che 3 SAT è np completo noi due passaggi dobbiamo fare. Il primo dobbiamo mostrare che 3 SAT appartenga ad NP. E secondo dobbiamo mostrare che 3 SAT è NP hardduo. Ok? Allora, secondo voi tre sat appartiene a NP o no? Sì. Come facciamo a dimostrarlo? Un sotto caso di perché è un sotto caso di sal. E se invece noi volessimo mostrarlo direttamente che appartiene a N+? Macchina non deterministica che lo calcola in tempo in tempo polinomiale. Che cosa dovrebbe fare questa macchina non deterministica? indovinare l'assegnazione perché tanto poi la la verifica se l'assegnazione è corretta polinomiale. Sì. Quindi una macchina non deterministica che risolve tre salti in tempo polinomiale che può fare? Fa un gess della soluzione se ci sta, dopodiché verifica che quello che ha gessato in effetti soddisfi la formula. questa, quindi il get iniziale viene fatto in tempo polinomiale perché dobbiamo semplicemente stabilire vero o falso per un numero di variabili che polinomiali, ok? Che stanno nell'input è questo. Dopodiché la fase di check lo si può fare in tempo più o meno quadratico perché dobbiamo semplicemente verificare che ciò che abbiamo in effetti soddisfi la formula. Tutto qua? Ok? Quindi 3 SAT sta in NP. Per mostrare che eh 3 SAT sia NP completo, ci manca da mostrare che 3 SAT sia NP arduo. E per fare questo mostriamo una riduzione da SAT a 3 SAT. Ok? [Musica] Quindi, come al solito, qual è il problema di partenza della riduzione? No, no, no, stiamo riducendo un problema a un altro. Qual è il problema da cui riduciamo sat? Qual è il problema a cui riduciamo tre sat? Cos'è un'istanza per SAT? una formula fai in CNF. Ok. Che cos'è un'istanza per 3at? Una formula è una formula PSAI in 3CNF. Ok? Quindi, se noi vogliamo mostrare che sia possibile ridurre SAT a 3 SAT, dobbiamo far vedere che esiste una trasformazione polinomiale che prende F, che è una formula in CNF generica, la trasforma in una formula psi in 3CNF tale che fai è soddisfaci solo se PSAI soddisfacile. Ok, questo è il nostro target, questo è il nostro obiettivo. Ci dobbiamo quindi inventare un modo di trasformare F in PSI. Ok? Allora, prendiamo fil. F sarà fatta da una un insieme di clausole C1 and C2 and bla bla bla and CM. Dov'è? Dov'è? Sì. Dobbiamo far vedere come arrivare da File Appside. Allora, questa cosa si può fare iterativamente tramite una serie di passaggi. Consideriamo che cosa facciamo? Facciamo passiamo da file a un certo f primo, ok? Che non è ancora la nostra formula psi finale, è una formula intermedia. Vediamo come si fa. Dopodiché il processo si può reiterare fino per ottenere fai secondo, fai terzo, bla bla, fino a quando arriviamo a Psit. Allora, noi facciamo così, consideriamo a turno le clausole C con I che provengono da f, no? Queste qui avranno dei letterali L1 or L2 or bla bla bla or LK. Ok? [Musica] E facciamo così, prendiamo queste C, le prendiamo una dopo l'altra, eh, tipo partiamo da C1, poi da C2, prendiamone una generica, C. Che facciamo? Andiamo a guardare i letterali. Se sono al +3, c con i viene ricopiata dentro fai primo, ok? Quindi non facciamo niente. Chiaro? Quindi sto trasformando F in una F prim primo che è una formula intermedia, non è ancora PS, ok? È una formula intermedia. Come la genero? Vado a guardare tutte le clausole una dopo l'altra di file. Ne prendo una, conto i letterali. Se non sono più di tre, quella clausola pari pari la metto dentro fai primo. Ok? Se sono più di 3, strettamente più di tre, faccio un giochino. Da c con i che sta in f, io genero due clausole C I primo e C e andremo a mettere dentro fa I primo C con i prim' sarà questa cosa qua. L1 or L2 or HI dove Hi è una nuova variabile, ok? Una cosa che non appariva in nessuna delle clausole. Pippo I, Topolino I, la chiamate come volete, è una è una fresh variable, ok? C con i secondo si fa in questo modo L3 or bla bla bla or LK or not H con I dove H con i è la variabile che compare anche nell'altra clausola. È chiaro che facciamo? Quindi prendiamo le clausole da f e le guardiamo a una a un. Se la clausola a me al più tre letterali non facciamo niente. Ok? Se la clausola C con i che proviene da F ha è strettamente più di letter di tre letterali, ne generiamo due da infilare dentro fai primo. Una è questa qua, L1 or L2 or HD e l'altra è L3 ork. Ok? Che taglia A C con i primo. Quanti letterali ci stanno in CON i primo? Tre. Quanti letterali ci stanno in Cond? Ce ne stanno uno in meno di prima. -2. Sì. -2 + 1. No, ce n'è uno in meno. Ok. Quindi in questa operazione di trasformazione abbiamo trasformato una clausola con tre letterali in due clausole in cui una c'ha tre letterali e l'altra ce ne ha uno di meno. Ok? Chiaro? In questo modo abbiamo generato f con i f prim'. Ok? Male che ci va in f primo. Fai primo. Quante clausole avremo? [Musica] Du. Sì. M M. Ok. Ripeto, noi prendiamo le clausole di f se sono così come sono, se sono minori di tre, il numero al più tre letterali, le scopiazziamo così. Se sono hanno più di tre letterari, le sdoppiamo, ok? Secondo quella regola là. La cosa interessante è che questa sdoppiatura produce una clausola di taglia tre letterali e una clausola di taglia, un letterale in meno. Male che ci va se sdoppiamo tutto. Ok? Noi avremo che il numero di clausole è 2 * n. Ok? Chiaro? Nessuno ci vieta di reiterare il processo su fai primo. Quindi se fai primo dopo questa prima riscrittura contiene ancora delle clausole con più di tre letterali. Io ripeto il processo. Fai secondo, non fai primo. Primo è quello che andremo in opera sul fai primo è quella che ottengo facendo questa operazione. Dopodiché io vado a guardare fai primo. Se dentro fai primo ci sono clausole con ancora più di tre letterali, ripeto il processo e ottengo un file secondo. Ok, ci siete? Cioè noi quindi questa procedura la possiamo reiterare più volte per ottenere un f secondo, un f terzo, un fai quarto, fino a quando arriviamo a una formula che non abbia più clausole con più di tre letterali. 3F al +3. Al + 3. Al +3. Sì, sì, sì, sì. Chiaro che facciamo? Ripeto. Sì. Ma con secondo cosa ci facciamo? Eh, noi consigliamo soltanto C primo. No, tu ne metti entrambi in C primo. Ah, second. Cioè, noi partiamo da C con I, generiamo due clausole e quelle lì entrambe le infiliamo in f primo, non solo una delle due. Ok? Chiaro il processo? Partiamo da Fai, guardiamo le sue clausole, ce le guardiamo, le mettiamo in un bel forro, ok? Le guardiamo una dopo l'altra. Se la clausola ha al più tre letterali, la prendiamo così com'è e la mettiamo dentro fai primo. Se la clausola che stiamo considerando di f ha più di tre letterali, noi in f primo ne andiamo a mettere due di clausole. Una è questa, eh, una è questa e l'altra è questa. Ok? C I primo avrà tre letterali. C avrà un letterale in meno di C con I. La fai primo che abbiamo ottenuto potrebbe o meno avere clausole con più di tre letterali. Se la fai primo a una clausola con più di tre letterali, ripetiamo il processo e otterremo una file secondo nel quale vi faccio notare la taglia delle clausole si sta riducendo, cioè abbiamo sempre abbiamo clausole sempre più corte fino a quando a un certo punto arriveremo a una formula fai di B R nel quale nel quale clausole con più di tre letterali non ce ne stanno più. Quella è la nostra psai. Ok? È chiaro? Se K è il numero di passaggi che dobbiamo fare per trasformare F in PSAI, cioè generiamo un f primo, poi un f secondo, un f terzo, bla bla bla bla. F PK, che quello è il nostro PSA, noi avremo ottenuto una formula il cui numero di clausole è K * M. Perché K * M e non 2^ K? Perché quando noi andiamo a splittare una clausola in due è solo la seconda che può essere più lunga di 3. Ok? Quindi a ogni iterazione noi avremo 2 m clausole, 3 m clausole, 4 m clausole fino a km. Questa cosa si può fare in tempo polinomiale? Sì, si fa in tempo polinomiale. Ci ci rimane da verificare che una tale trasformazione trasforma istanze s di sat in istanze s diat. Ok? Sì. Eh, quindi 2 sta riferirsi a fino a quanto si riesce a espandere in ogni file e cioè se io passo da file a f primero di clausole in file primo e il blocchio delle clausole che sta in file, mentre il numero di fai alla fine non si sa più ori fare, no? però è bounded da K * M, dove K è il numero massimo di letterali che appare in una clausola di F. Sì, sto facendo adesso vi mostro prima ci focalizziamo su questo e poi poi lo vediamo se c'è tempo perché abbiamo un quarto d'ora. Alr, è chiaro come avviene la trasformazione? Quindi noi prendiamo una formula CNF generica, la trasformiamo in una formula 3CNF. Quello che adesso noi dobbiamo mostrare è che quello a cui arriviamo, la psai a cui arriviamo è equivalente, cioè che la fai di partenza è soddisfacbile se solo se la psi di arrivo è soddisfacile. Ok? Primo verso, trasformiamo da fai soddisfacbile implica psai soddisfacile. Ok? Questa è la cosa di cui ci occupiamo di mostrare ora. Ok? Supponiamo che fai sia soddisfacile. Se fai è soddisfaccibile, allora esiste un assegnamento sigma per le variabili buleane di festa variabile gli dai vero, a quest'altra variabile gli dai falso, a quest'altra pure falso, a quest'altra vera e son. Quindi sigma è un assegnamento di verità per le variabili in f tale che fai è soddisfatta, cioè viene valutata vera da questo assegnamento di di verità. Ok? Allora, quello che noi dobbiamo mostrare è che se un tale sigma esiste, allora esiste un tau ottenuto da sigma che è un assegnamento di verità per psai che soddisfai. Ok? Questo è il nostro intento. Stiamo partendo un attimo. Questo è sigma. Quello è E Sì, questo è mo te lo dico. A2. Questo è tao di sigma. Ok. È chiaro il motivo per cui facciamo questo. Noi dobbiamo mostrare che fai, stiamo assumendo che fai sia soddisfacile. Dobbiamo mostrare che anche PSI lo è. Come facciamo a mostrare che PSAI è soddisfacbile se esiste un assegnamento di verità che lo soddisf? Allora, che cosa facciamo? Siccome FA è soddisfaccibile esiste un assegnamento di verità che lo soddisfa. Noi vogliamo mostrare che da da partendo da sigma esiste un assegnamento di verità basato su sigma che soddisfi PSAI, da cui otterremo che PSAI è soddisfacbile pure. Ok? Alright. Allora, come avete visto nella trasformazione da FI verso PSAI, PSAI ha ottenuto una serie di variabili aggiuntive fresh che in sigma non ci stavano. Quindi PSAI ha più roba che non fai. Allora, facci come definiamo tau sigma? TU sigma è ottenuta partendo da sigma ricopiando l'assegnamento che c'è in sigma. Ok? Quindi se x con 1 era valutata vera in sigma, x1 è valutato vero in ta sigma. Ok? Però tau sigma ha tutte quelle h aggiuntive che in sigma non ci stavano, quindi dobbiamo dare un assegnamento di verità per quello. Allora, guardate questa cosa. Consideriamo una generica clausola di f. Quello che mostreremo ora è che se più più nello specifico il nostro obiettivo è mostrare che da fai soddisfacbile otteniamo una psi soddisfacbile, però nel dettaglio quello che faremo ora è mostrare che se fai è soddisfacbile, fai primo è soddisfacile, da cui poi per induzione tutto il resto rimane soddisfacbile per ragioni simili. Ok? Allora, sappiamo che sigma soddisfa fai, quindi sigma deve soddisfare anche questa clausola di f. Per soddisfare quella clausola di f sigma deve rendere uno di quei letterali veri, almeno uno, ok? Senò non la starebbe soddisfacendo. Ci siete? Questa C con I noi l'abbiamo divisa in C' e Condo. Alri. Sigma soddisfa C i. Significa che dentro CON i c'è un LJ che è vero causa sigma. Lj appare per costruzione della riduzione o in CON i pr' o in CON i second. Se appare in CONI primo, tausigma sta verificando, rende vero C con i primo e non sappiamo dire ancora molto di CON i second. Se LJ appare in C con i secondo, allora ta sigma starà verificando C con i second. Ma allora l'altra clausola, quella del l'altra della coppia, come facciamo a verificarla? Abbiamo completa controllo su queste variabili qua, gli diamo il valore che ci serve e noi siamo in grado di verificare l'altra clausola della coppia. Ok? Quindi se fai è soddisfacbile siamo in grado di soddisfare anche fai primo. È chiaro? Ci manca ora da mostrare il verso opposto. Formalmente col cappellet molto veloce se riesce. Ok, abbiamo poco tempo, però ci sta tutto il dettaglio sugli appunti di Calau. Ah, ok. Sì, sì, sì, sì. Cioè, cioè là lo là lo leggete, ripeto, la questione è sigma sigma soddisfa tutte le clausole di fil, ok? Per soddisfare la clausola CON i, uno dei suoi letterali deve essere vero per forza. Questo letterale durante la riscrittura da fai a fai con fai primo o è finita in C i primo o è finita in C. Quindi un tausigma che dà lo stesso valore di verità a quel letterale soddisfarrà una delle due clausole della coppia. L'altra noi la possiamo soddisfare dando un valore di verità opportuno ad h con i. Tutto qua. Chiaro? Altro verso, dobbiamo mostrare che se psai è soddisfacbile, allora fai è soddisfacile. Anche in questo caso ci concentreremo su uno dei micropassi, cioè quello che noi mostriamo è che se fai primo è soddisfa allora lo è anche fai. Ok? Supponiamo che fai primo sia soddisfacile. Ok? Da ciò esiste tau che soddisfa fai primo. Ok. Quindi che cosa avremo? Noi avremo che eh no, un attimo or L2 or Hi, vedo C di secondo e L2 or bla bla bla ork. Ok. Come L3? Sì. Ok? Allora, noi abbiamo l'assegnamento tau che soddisfa fai primo. Se tau soddisfa fai primo, soddisfa tutte le sue clausole, no? Allora, le clausole di F primo sono di due tipi, sostanzialmente, quelle che ci siamo completamente ricopiate da F e quelle che provengono dallo split di C di CONI. Quelle che ci siamo ricopiate da file, se sono soddisfatte da ta potranno essere soddisfatte anche dentro F. Ripeto, se noi abbiamo un assegnamento di verità tao per f primo, noi possiamo ottenere un assegnamento di verità tau sigma, no, sigma ta sigma ta per f. Ok, quindi partiamo da un tao per feniamo un sigma tau per f. Il tao di fare un valore di verità a x 1, x 2, x 3, bla bla bla + h1, h2, h. Abbiamo tutta una serie di cose aggiuntive, no? Allora, Tau deve verificare F primo. Vuol dire che sta rendendo vere tutte le clausole di f primo. Prendiamo una clausola di f primo. Questa clausola di f due sono le possibilità. O ce l'eravamo ricopiata direttamente da F oppure è una delle clausole di una coppia proveniente da una sola clausola di F. Primo caso, se la clausola proveniva, se questa clausola di fi primo proveniva direttamente dalla clausola di f perché l'abbiamo copiata, né in quella clausola di faio, ci stanno solo le variabili standard. Quindi quella clausola lì viene resa vera da Tau perché TAU sta dando un valore di verità a un letterale là dentro che sta anche nella clausola di file. Quindi se noi prendiamo quell'assegnamento di verità per quella variabile lì stiamo possiamo verificare anche la clausola di partenza in file. Ok? Il problema è se noi abbiamo che le clausole che stiamo guardando di Fo sono di quelle accoppiate. Allora, guardate questa cosa qua. I Se noi prendiamo le clausole di fai primo a coppie, noi avremo che in una appare hi e nell'altra appare not HI. Quindi se questa è verificata da Tao e quest'altra è verificata da Tao, non è che entrambe possono essere verificate perché questo è vero e questo è vero perché sono una all'opposta dell'altra. Quindi una verrà verificata da lui e l'altra verrà verificata per qualcosa qua. Oppure una è verificata da questo e l'altra è verificata per questo pezzo qua. In ogni caso significa che c'è data una coppia. Se le prendiamo a coppie queste clausole, una di quelle due clausole deve essere verificato da uno di questi letterali che stavano dove? in Ok, qua ho sbagliato che stavano nella clausola C con i di fil, quindi quel letterale vero che sia qua o qua sarà qua dentro dentro fai e di conseguenza quella clausola dentro fai sarà resa vera. È chiaro? Quindi questa cosa ci mostra che cosa? che questo processo di trasformazione trasforma fai soddisfaccibile in una fai primo soddisfacbile e che se siamo arrivati a una fai primo soddisfacbile era perché partivamo da una file soddisfacile. Qui abbiamo una catena di trasformazione tale per cui da fai arriviamo a PSI soddisfacile. Per questa ragione noi siamo in grado di trasformare istanze sì di CNF in istanze sì di 3 CNF e istanze no di CNF in istanze no di 3 CNF da cui 3 SAT è NP arduo perché SAT è NP2. Ok, gli ultimi minuti per dare un commento e poi vi lascio un semplicissimo esercizio. Come un collega mi chiedeva, dice "Ma allora noi questa funzione di di restrizione delle clausole possiamo farla fino a ottenere formule molto piccole, formule con clausole di due letterali o formule con clausole di tre letterali?" No, questa cosa non è possibile perché supponiamo di avere una c con i fatta in questo modo. Dove me l'ero segnata? qua che ne so L1 or L2 or L3. Supponiamo di voler ottenere una 2 CNF. Che cosa possiamo avere? Abbiamo C con i prim che è L1 or HI e poi abbiamo una cise che è L2 or L3 or not HI. Questa qui ha una taglia nuovamente di tre, cioè noi sotto 3 non possiamo scendere. Di fatto si può mostrare che il problema due SAT, ma non lo vediamo perché non abbiamo tempo, il problema due SAT appartiene a P, cioè se le clausole sono molto piccole con al + 2, allora il terminal diventa polinomiale. C'è una ragione di fondo per cui questo avviene, perché non c'è un'esplosione combinatorica. Sostanzialmente la dimostrazione mostrerebbe, però non abbiamo il tempo di vederla, tale per cui due SAT è un problema molto più semplice di tre sat. Ecco perché non possiamo ridurre 3 SAT a 2 SAT sostanzialmente perché 3 SAT è np completo mentre 2 SAT è polinomiale. Esercizio per casa, dimostrare che exact trat completo. Cos'è exact? Sono le formule tre sat in cui le clausole hanno esattamente tre letterali. Ok? Quindi tre SAT normale clausole hanno al più tre letterali. In exact tre sat le clausole delle formule hanno esattamente tre letterali. La riduzione che vi suggerisco è questa qua. Riducete tre sat a exact tre sat. Ok? E con questo chiudiamo. [Musica]