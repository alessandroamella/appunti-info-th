\documentclass[a4paper]{article}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[a4paper, total={6in, 9in}]{geometry} % Aumentato lo spazio verticale per i diagrammi
\usepackage{minted} % Per il codice (se necessario, non strettamente usato in questa lezione)
\usepackage{mathpazo} % Font più gradevole
\usepackage{fancyhdr} % Per header e footer
\usepackage{amsthm} % Per ambienti teorema, definizione
\usepackage{tikz} % Per diagrammi
\usetikzlibrary{automata,positioning,arrows.meta,shapes.geometric,matrix} % Carico librerie utili per tikz
\usepackage{enumerate} % Per liste enumerate con personalizzazione

% Definizione degli ambienti
\newtheorem{theorem}{Teorema}
\newtheorem{definition}{Definizione}
\newtheorem{example}{Esempio}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposizione}
\newcommand{\blankS}{\ensuremath{\not\text{b}}} % Standardized Blank Symbol
\theoremstyle{remark} % Cambio lo stile per le osservazioni
\newtheorem{remark}{Osservazione}


% Impostazioni hyperref per i link nel PDF
\hypersetup{
    pdftitle={Lezione di Informatica Teorica: Macchina di Turing Universale e Linguaggi Indecidibili},
    pdfauthor={Appunti da Trascrizione AI},
}

% Impostazioni per header e footer
\pagestyle{fancy}
\fancyhf{} % Pulisce tutti gli header e footer
\fancyhead[L]{\textit{Lezione 11: Macchina di Turing Universale e Indecidibilità}} % Intestazione sinistra
\fancyfoot[C]{\thepage} % Numero di pagina centrato

\title{Lezione 11: Macchina di Turing Universale e Linguaggi Indecidibili}
\author{Appunti potenziati da Trascrizione Automatica}
\date{\today}

\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Introduzione e Ripasso}

Nella lezione precedente abbiamo introdotto le Macchine di Turing Non-Deterministiche (NTM) e le classi di problemi decidibili (R) e semi-decidibili (RE).

\begin{itemize}
    \item La simulazione di una \textbf{NTM} da parte di una \textbf{DTM} è possibile, sebbene con un costo significativo in termini di tempo di esecuzione (esponenziale). Ai fini della sola \textit{decidibilità} di un problema, l'efficienza temporale non è un fattore determinante: l'importante è che la macchina \textbf{termini sempre}.
    \item La classe \textbf{R} (linguaggi \textbf{Ricorsivi}) include tutti i problemi \textbf{decidibili}, cioè per i quali esiste un algoritmo (una TM) che termina sempre, fornendo una risposta definita (sì/no).
    \item La classe \textbf{RE} (linguaggi \textbf{Ricorsivamente Enumerabili}) include i problemi \textbf{semi-decidibili}. Per questi, esiste una TM che garantisce di fermarsi e rispondere "sì" in tempo finito se la stringa appartiene al linguaggio. Tuttavia, se la stringa non appartiene, la macchina potrebbe non terminare mai (andare in loop). Questo li rende, di fatto, non decidibili.
    \item Esistono problemi completamente \textbf{indecidibili}, che non rientrano né in R né in RE. Per questi non è garantita alcuna risposta, né per il "sì" né per il "no".
\end{itemize}

\section{La Macchina di Turing Universale (UTM)}

Le Macchine di Turing (TM) studiate finora sono "specializzate": la loro funzione di transizione è fissata e definisce un unico compito. I computer moderni, al contrario, sono \textbf{programmabili}: possono eseguire programmi diversi. Per colmare questa apparente discrepanza, introduciamo il concetto di \textbf{Macchina di Turing Universale (UTM)}.

\begin{definition}[Macchina di Turing Universale (UTM)]
Una Macchina di Turing Universale ($M_U$) è una TM speciale il cui programma è fisso, ma è progettata per \textbf{interpretare e simulare il comportamento di qualsiasi altra Macchina di Turing} ($M$) quando le viene fornita una descrizione (codifica) di $M$ e l'input $w$ su cui $M$ dovrebbe operare.
\end{definition}

\subsection{Codifica di una Macchina di Turing}

Per dare in pasto una TM a un'altra, dobbiamo trasformare il suo "programma" (la funzione di transizione) in una stringa, ad esempio una stringa binaria. Esistono infiniti modi per farlo, ne vediamo uno.

Una generica istruzione della funzione di transizione $\delta$ ha la forma:
\[ \delta(q_i, X_j) = (q_k, X_l, D_m) \]

La codifica si basa sull'idea di rappresentare ogni indice con un numero corrispondente di zeri.
\begin{enumerate}
    \item \textbf{Stati ($q_i$)}: codificati con $i$ zeri.
    \begin{itemize}
        \item $q_1$ (stato iniziale) $\rightarrow 0$
        \item $q_2$ (stato accettante) $\rightarrow 00$
        \item $q_5 \rightarrow 00000$
    \end{itemize}
    \item \textbf{Simboli Nastro ($X_j$)}: codificati con $j$ zeri.
    \begin{itemize}
        \item $X_1$ (simbolo '0') $\rightarrow 0$
        \item $X_2$ (simbolo '1') $\rightarrow 00$
        \item $X_3$ (simbolo blank $\blankS$) $\rightarrow 000$
    \end{itemize}
    \item \textbf{Direzioni ($D_m$)}: codificate con $m$ zeri.
    \begin{itemize}
        \item $D_1$ (Sinistra, L) $\rightarrow 0$
        \item $D_2$ (Destra, R) $\rightarrow 00$
    \end{itemize}
    \item \textbf{Separatori}:
    \begin{itemize}
        \item Il simbolo `1` separa i componenti di una singola transizione.
        \item La sequenza `11` separa le diverse transizioni tra loro.
    \end{itemize}
\end{enumerate}

\begin{example}[Esempio di codifica]
Codifichiamo la transizione: $\delta(q_3, \blankS) = (q_5, 0, R)$
\begin{itemize}
    \item $q_3 \rightarrow \textbf{000}$
    \item $\blankS$ è $X_3 \rightarrow \textbf{000}$
    \item $q_5 \rightarrow \textbf{00000}$
    \item $0$ è $X_1 \rightarrow \textbf{0}$
    \item $R$ è $D_2 \rightarrow \textbf{00}$
\end{itemize}
Assemblando i pezzi con il separatore `1`, la codifica di questa singola transizione è:
\[ \underbrace{000}_{q_3} \mathbf{1} \underbrace{000}_{X_3} \mathbf{1} \underbrace{00000}_{q_5} \mathbf{1} \underbrace{0}_{X_1} \mathbf{1} \underbrace{00}_{D_2} \]
La codifica completa di una TM, indicata con $\langle M \rangle$, è la concatenazione di tutte le sue transizioni, separate da `11`:
\[ \text{Codifica}(\delta_1) \mathbf{11} \text{Codifica}(\delta_2) \mathbf{11} \dots \]
\end{example}

\begin{remark}
Non tutte le stringhe binarie corrispondono a una TM valida. Per convenzione, le stringhe mal formate (es. `01110...`) codificano una TM "banale" che rifiuta ogni input (il suo linguaggio è $\emptyset$).
\end{remark}

\subsection{Architettura e Funzionamento della UTM}

La UTM ($M_U$) è spesso descritta come una TM a più nastri per rendere più chiara la sua funzione. Supponiamo usi 4 nastri. L'input per $M_U$ è la coppia $(\langle M \rangle, w)$, dove $\langle M \rangle$ è la codifica di una TM e $w$ è l'input per $M$. Questi sono scritti sul primo nastro, separati da una sequenza speciale (es. `111`).

\begin{figure}[h!]
\centering
\begin{tikzpicture}[font=\sffamily\small]
    \node[draw, rectangle, minimum height=3cm, minimum width=6cm] (mu) at (0,0) {$M_U$};

    % Nastro 1
    \draw (-5,-1.2) -- (mu.west |- 0,-1.2);
    \node[anchor=east] at (-5.2, -1.2) {Nastro 1 (Programma di M):};
    \node[anchor=west, font=\ttfamily] at (-4.8, -1.2) {00101...11...};
    
    % Nastro 2
    \draw (-5,-0.4) -- (mu.west |- 0,-0.4);
    \node[anchor=east] at (-5.2, -0.4) {Nastro 2 (Nastro di M):};
    \node[anchor=west, font=\ttfamily] at (-4.8, -0.4) {... $\blankS$ $\blankS$ $\underline{00}$ 000 $\blankS$ ...};
    
    % Nastro 3
    \draw (-5,0.4) -- (mu.west |- 0,0.4);
    \node[anchor=east] at (-5.2, 0.4) {Nastro 3 (Stato di M):};
    \node[anchor=west, font=\ttfamily] at (-4.8, 0.4) {000};
    
    % Nastro 4
    \draw (-5,1.2) -- (mu.west |- 0,1.2);
    \node[anchor=east] at (-5.2, 1.2) {Nastro 4 (Ausiliario):};
    \node[anchor=west, font=\ttfamily] at (-4.8, 1.2) {(scratchpad)};
    
\end{tikzpicture}
\caption{Architettura a 4 nastri di una Macchina di Turing Universale.}
\label{fig:utm}
\end{figure}

I ruoli dei nastri sono (vedi Figura \ref{fig:utm}):
\begin{enumerate}
    \item \textbf{Nastro 1 (Input/Programma $\langle M \rangle$)}: Contiene la codifica della TM $M$. Questo nastro è di sola lettura. È il "manuale di istruzioni" che $M_U$ consulta.
    \item \textbf{Nastro 2 (Nastro Similato di $M$)}: Rappresenta il nastro della TM $M$. Qui viene inizialmente copiata e ricodificata la stringa $w$. La testina di $M_U$ su questo nastro simula la testina di $M$.
    \item \textbf{Nastro 3 (Stato Similato di $M$)}: Contiene la codifica dello stato corrente di $M$ (es. `000` per $q_3$).
    \item \textbf{Nastro 4 (Scratchpad/Ausiliario)}: Nastro di servizio per operazioni temporanee, come copiare pezzi di nastro per fare spazio quando un simbolo viene sostituito da un altro con una codifica di lunghezza diversa.
\end{enumerate}

\subsubsection{Passi di Simulazione}
$M_U$ esegue un ciclo infinito di "fetch-decode-execute":
\begin{enumerate}
    \item \textbf{Fetch}: $M_U$ legge lo stato corrente di $M$ (dal Nastro 3) e il simbolo sotto la testina simulata (dal Nastro 2).
    \item \textbf{Decode}: Usando questa coppia (stato, simbolo), $M_U$ cerca sul Nastro 1 (il "programma" di $M$) la transizione corrispondente.
    \item \textbf{Execute}: Trovata la transizione $\delta(q_i, X_j) = (q_k, X_l, D_m)$, $M_U$ aggiorna la simulazione:
    \begin{itemize}
        \item Scrive la codifica del nuovo stato $q_k$ sul Nastro 3.
        \item Scrive la codifica del nuovo simbolo $X_l$ sul Nastro 2 (usando il Nastro 4 se necessario).
        \item Sposta la testina sul Nastro 2 nella direzione $D_m$.
    \end{itemize}
    \item Questo ciclo si ripete. Se la simulazione di $M$ raggiunge lo stato di accettazione (es. $q_2$, codificato `00`), $M_U$ si ferma e accetta. Se $M$ va in loop, anche $M_U$ andrà in loop.
\end{enumerate}

\subsection{Connessione con i Computer Reali}
I nostri computer sono l'equivalente pratico di una UTM. Il loro "programma" immutabile non è l'applicazione che eseguiamo, ma il \textbf{microcodice della CPU}. La CPU esegue un ciclo fisso (fetch-decode-execute) per leggere istruzioni dalla memoria (il nostro programma) ed eseguirle. Questo risolve il dilemma: i computer non "cambiano" il loro programma fondamentale, ma ne hanno uno fisso (il microcodice) che li rende universali, capaci di eseguire qualsiasi altro programma.

\section{Linguaggi Indecidibili: L'Argomento di Diagonalizzazione}

Esistono problemi che nessuna TM può risolvere. La dimostrazione classica usa l'argomento di diagonalizzazione di Cantor.

\subsection{Enumerazione di Stringhe e Macchine di Turing}

\begin{enumerate}
    \item \textbf{Enumerazione di stringhe binarie ($\Sigma^*$)}: L'insieme di tutte le stringhe binarie $\Sigma^*$ è \textbf{numerabile} (infinito ma "contabile"). Possiamo ordinarle (es. per lunghezza, poi lessicograficamente: $\epsilon, 0, 1, 00, 01, \dots$) e considerare la $i$-esima stringa $w_i$. La sua cardinalità è $\aleph_0$, la stessa dei numeri naturali.
    \item \textbf{Enumerazione delle TM}: Poiché ogni TM può essere codificata come una stringa binaria, anche l'insieme di tutte le TM è \textbf{numerabile}. Possiamo parlare della $i$-esima TM, $M_i$.
\end{enumerate}

\subsection{Costruzione del Linguaggio di Diagonalizzazione ($L_D$)}
Immaginiamo una tabella infinita:
\begin{itemize}
    \item Le \textbf{colonne} sono le stringhe binarie enumerate: $w_1, w_2, w_3, \dots$
    \item Le \textbf{righe} sono le TM enumerate: $M_1, M_2, M_3, \dots$
    \item La cella $(i, j)$ contiene $1$ se $M_i$ \textbf{accetta} la stringa $w_j$, e $0$ altrimenti.
\end{itemize}

Ogni riga $i$ è il \textbf{vettore caratteristico} del linguaggio $L(M_i)$.

\begin{figure}[h!]
\centering
\begin{tikzpicture}[font=\sffamily\small]
    \matrix (m) [matrix of math nodes,
                 nodes in empty cells,
                 nodes={minimum width=1.2cm, minimum height=0.8cm},
                 column sep=0pt, row sep=0pt,
                 left delimiter={[}, right delimiter={]}]
    {
        & w_1 & w_2 & w_3 & w_4 & \dots \\
    M_1 & \mathbf{0} & 1 & 0 & 0 & \dots \\
    M_2 & 1 & \mathbf{1} & 0 & 1 & \dots \\
    M_3 & 0 & 0 & \mathbf{0} & 1 & \dots \\
    M_4 & 1 & 0 & 0 & \mathbf{1} & \dots \\
    \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
    };
    \draw (m-1-1.north west) -- (m-1-6.north east);
    \draw (m-2-1.north west) -- (m-2-1.south west);
    
    \node[right=0.5cm of m, align=left] (diag) {Diagonale $D = 0101\dots$ \\ Complemento $\overline{D} = 1010\dots$};
    \draw[->, thick, red] (diag.west) to[out=180, in=-30] (m-2-2.center);
    \draw[->, thick, red] (diag.west) to[out=180, in=-30] (m-3-3.center);
    \draw[->, thick, red] (diag.west) to[out=180, in=-30] (m-4-4.center);
    \draw[->, thick, red] (diag.west) to[out=180, in=-30] (m-5-5.center);
    
\end{tikzpicture}
\caption{La tabella di diagonalizzazione. La diagonale $D$ viene estratta e complementata per costruire un nuovo linguaggio che non può trovarsi in nessuna riga della tabella.}
\label{fig:diag}
\end{figure}

Il procedimento è (vedi Figura \ref{fig:diag}):
\begin{enumerate}
    \item \textbf{Prendere la diagonale ($D$)}: È la sequenza di bit nelle celle $(i,i)$. Nell'esempio, $D = 0101\dots$. Questo bit ci dice se la macchina $M_i$ accetta la "sua" stringa $w_i$.
    \item \textbf{Complementare la diagonale ($\overline{D}$)}: Invertiamo ogni bit. Nell'esempio, $\overline{D} = 1010\dots$.
    \item \textbf{Definire $L_D$}: Il linguaggio $L_D$ è quello che ha $\overline{D}$ come suo vettore caratteristico.
\end{enumerate}

Formalmente, la definizione di $L_D$ è:
\begin{definition}[Linguaggio di Diagonalizzazione $L_D$]
$L_D = \{ w_i \mid M_i \text{ non accetta } w_i \}$.
In altre parole, $L_D$ contiene le codifiche di macchine ($w_i = \langle M_i \rangle$) che rifiutano (o non terminano su) la propria codifica come input.
\end{definition}

\begin{example}[Costruzione di $L_D$ con un esempio concreto]
Per rendere la costruzione più chiara, facciamo un esempio con 4 macchine e 4 stringhe:

\textbf{Stringhe enumerate:}
\begin{itemize}
    \item $w_1 = 01$ (codifica della macchina $M_1$)
    \item $w_2 = 110$ (codifica della macchina $M_2$)
    \item $w_3 = 0011$ (codifica della macchina $M_3$)
    \item $w_4 = 1001$ (codifica della macchina $M_4$)
\end{itemize}

\textbf{Comportamento delle macchine:}
\begin{center}
\begin{tabular}{c|cccc}
 & $w_1$ & $w_2$ & $w_3$ & $w_4$ \\
\hline
$M_1$ & \textbf{0} & 1 & 0 & 1 \\
$M_2$ & 1 & \textbf{1} & 0 & 0 \\
$M_3$ & 0 & 1 & \textbf{0} & 1 \\
$M_4$ & 1 & 0 & 1 & \textbf{1} \\
\end{tabular}
\end{center}

\textbf{Lettura della tabella:}
\begin{itemize}
    \item $M_1$ NON accetta $w_1$ (sua propria codifica) → $w_1 \in L_D$
    \item $M_2$ accetta $w_2$ (sua propria codifica) → $w_2 \notin L_D$
    \item $M_3$ NON accetta $w_3$ (sua propria codifica) → $w_3 \in L_D$
    \item $M_4$ accetta $w_4$ (sua propria codifica) → $w_4 \notin L_D$
\end{itemize}

\textbf{Quindi:} $L_D = \{w_1, w_3\} = \{01, 0011\}$

\textbf{La diagonale:} $D = 0101$ (i valori nelle celle $(i,i)$)
\textbf{Il complemento:} $\overline{D} = 1010$ (che corrisponde al vettore caratteristico di $L_D$)

\textbf{Perché $L_D$ non può essere riconosciuto da nessuna macchina nella tabella?}
Se esistesse una macchina $M_k$ che accetta esattamente $L_D$, dovremmo avere una contraddizione:
\begin{itemize}
    \item Se $M_k$ accetta $w_k$, allora $w_k \in L(M_k) = L_D$, ma per definizione di $L_D$ questo significa che $M_k$ NON dovrebbe accettare $w_k$.
    \item Se $M_k$ non accetta $w_k$, allora $w_k \notin L(M_k) = L_D$, ma per definizione di $L_D$ questo significa che $M_k$ DOVREBBE accettare $w_k$.
\end{itemize}
In entrambi i casi, otteniamo una contraddizione!
\end{example}

\begin{theorem}
Il linguaggio $L_D$ non appartiene alla classe RE (non è ricorsivamente enumerabile).
\end{theorem}

\begin{proof}[Dimostrazione per contraddizione]
Supponiamo che $L_D$ sia in RE. Allora, per definizione, deve esistere una TM, chiamiamola $M_k$, che accetta $L_D$. Poiché la nostra tabella elenca \textit{tutte} le possibili TM, $M_k$ deve trovarsi alla riga $k$.
Ora, consideriamo la stringa $w_k$ (che è la codifica di $M_k$). Chiediamoci: $w_k$ appartiene a $L(M_k)$?

\begin{enumerate}[(i)]
    \item \textbf{Caso 1: Supponiamo che $M_k$ accetti $w_k$}.
    \begin{itemize}
        \item Se $M_k$ accetta $w_k$, allora per definizione di $L_D$, $w_k$ \textbf{non} dovrebbe appartenere a $L_D$.
        \item Ma noi abbiamo assunto che $M_k$ è la macchina che accetta $L_D$. Quindi se $w_k \notin L_D$, $M_k$ \textbf{non} dovrebbe accettare $w_k$.
        \item Questo è una contraddizione: $M_k$ accetta $w_k \iff M_k$ non accetta $w_k$.
    \end{itemize}

    \item \textbf{Caso 2: Supponiamo che $M_k$ non accetti $w_k$}.
    \begin{itemize}
        \item Se $M_k$ non accetta $w_k$, allora per definizione di $L_D$, la stringa $w_k$ \textbf{deve} appartenere a $L_D$.
        \item Ma, di nuovo, $M_k$ è la macchina che accetta $L_D$. Se $w_k \in L_D$, allora $M_k$ \textbf{deve} accettare $w_k$.
        \item Anche questa è una contraddizione: $M_k$ non accetta $w_k \iff M_k$ accetta $w_k$.
    \end{itemize}
\end{enumerate}
In entrambi i casi, giungiamo a una palese contraddizione. L'unica cosa che può essere sbagliata è la nostra assunzione iniziale. Pertanto, \textbf{non può esistere} una TM $M_k$ che accetta $L_D$. Questo significa che $L_D$ non è ricorsivamente enumerabile ($L_D \notin RE$).
\end{proof}

\subsection{Intuizione sull'Esistenza di Linguaggi Indecidibili}
La ragione profonda è un problema di "numeri":
\begin{itemize}
    \item L'insieme di tutte le TM (e quindi di tutti gli algoritmi) è \textbf{numerabile} (cardinalità $\aleph_0$).
    \item L'insieme di tutti i possibili \textbf{linguaggi} su $\Sigma^*$ ha la cardinalità del \textbf{continuo} ($2^{\aleph_0}$), che è strettamente maggiore di $\aleph_0$.
\end{itemize}
Ci sono "infinitamente più" linguaggi che algoritmi per riconoscerli. È inevitabile che esistano linguaggi per i quali non esiste alcun algoritmo. $L_D$ è un esempio concreto di uno di questi.

\section{Proprietà sui Linguaggi R e RE}

Introduciamo due teoremi fondamentali che legano le classi R e RE tramite l'operazione di complemento. Il complemento di un linguaggio $L$, denotato $\overline{L}$, è l'insieme di tutte le stringhe che non sono in $L$ ($\overline{L} = \Sigma^* \setminus L$).

\begin{theorem}[Chiusura di R sotto Complemento]
Se un linguaggio $L$ è in R (è ricorsivo), allora anche il suo complemento $\overline{L}$ è in R.
\end{theorem}
\begin{proof}
Se $L \in R$, esiste una TM $M_L$ che \textbf{decide} $L$. Questo significa che $M_L$ termina sempre, accettando se $w \in L$ e rifiutando se $w \notin L$.
Possiamo costruire una nuova TM $M_{\overline{L}}$ che inverte la risposta di $M_L$:
$M_{\overline{L}}$ su input $w$:
\begin{enumerate}
    \item Simula $M_L$ su $w$.
    \item Poiché $M_L$ termina sempre, aspettiamo la sua risposta.
    \item Se $M_L$ accetta, $M_{\overline{L}}$ rifiuta. Se $M_L$ rifiuta, $M_{\overline{L}}$ accetta.
\end{enumerate}
Dato che $M_L$ termina sempre, anche $M_{\overline{L}}$ terminerà sempre. Quindi $M_{\overline{L}}$ decide $\overline{L}$, il che significa $\overline{L} \in R$.
\end{proof}

\begin{theorem}[Condizione per R]
Un linguaggio $L \in R$ se e solo se sia $L$ che il suo complemento $\overline{L}$ sono in RE.
\[ L \in R \iff (L \in RE \land \overline{L} \in RE) \]
\end{theorem}
\begin{proof}
($\Rightarrow$) Se $L \in R$, allora $L \in RE$ (perché R è un sottoinsieme di RE). Per il teorema precedente, anche $\overline{L} \in R$, e quindi $\overline{L} \in RE$.

($\Leftarrow$) Questa è la parte più interessante. Supponiamo $L \in RE$ e $\overline{L} \in RE$.
\begin{itemize}
    \item Esiste una TM $M_L$ che accetta $L$ (si ferma sui "sì" per $L$).
    \item Esiste una TM $M_{\overline{L}}$ che accetta $\overline{L}$ (si ferma sui "sì" per $\overline{L}$, che sono i "no" per $L$).
\end{itemize}
Possiamo costruire un \textbf{decisore} $M_{decider}$ per $L$ eseguendo $M_L$ e $M_{\overline{L}}$ "in parallelo".

\begin{figure}[h!]
\centering
\begin{tikzpicture}[font=\sffamily\small, node distance=1.5cm, -{Stealth}]
    \node (input) {$w$};
    \node[draw, rectangle, right=of input] (splitter) {Copia};
    \node[draw, rectangle, above right=0.5cm and 1cm of splitter] (ML) {$M_L$};
    \node[draw, rectangle, below right=0.5cm and 1cm of splitter] (MLbar) {$M_{\overline{L}}$};
    \node[draw, ellipse, right=of ML] (accept) {Accetta};
    \node[draw, ellipse, right=of MLbar] (reject) {Rifiuta};

    \draw (input) -- (splitter);
    \draw (splitter.north) |- (ML.west);
    \draw (splitter.south) |- (MLbar.west);
    \draw (ML.east) -- (accept.west) node[midway, above] {se $M_L$ accetta};
    \draw (MLbar.east) -- (reject.west) node[midway, below] {se $M_{\overline{L}}$ accetta};
\end{tikzpicture}
\caption{Simulazione parallela per decidere $L$. Poiché $w$ deve stare o in $L$ o in $\overline{L}$, una delle due macchine è garantita a fermarsi.}
\label{fig:parallel}
\end{figure}

$M_{decider}$ su input $w$ (vedi Figura \ref{fig:parallel}):
\begin{enumerate}
    \item Esegue un passo di $M_L$, poi un passo di $M_{\overline{L}}$, poi un altro passo di $M_L$, e così via, alternandoli.
    \item Poiché ogni stringa $w$ o appartiene a $L$ o a $\overline{L}$, una delle due macchine ($M_L$ o $M_{\overline{L}}$) è \textbf{garantita} a fermarsi e accettare.
    \item Se $M_L$ si ferma e accetta, allora $M_{decider}$ si ferma e \textbf{accetta} $w$.
    \item Se $M_{\overline{L}}$ si ferma e accetta, allora $M_{decider}$ si ferma e \textbf{rifiuta} $w$.
\end{enumerate}
In questo modo, $M_{decider}$ termina sempre su ogni input, decidendo correttamente l'appartenenza a $L$. Quindi $L \in R$.
\end{proof}

\end{document}